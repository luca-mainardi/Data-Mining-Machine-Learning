{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULQqLq0p4Kxs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import approx_fprime\n",
        "from math import log, exp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38b7TBVYyp_i"
      },
      "source": [
        "## Gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1z_E6Nq7nLo"
      },
      "source": [
        "###1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soWATtzD4TB1",
        "outputId": "833d5fe3-3b0e-4b55-e5a1-53bc9f9dfd51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.09322769334062\n",
            "1.09322769334062\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    return -np.log(1/(1+np.exp(-x[0]-x[1]))) - np.log(1/(1+np.exp(-1.5*x[0]-x[1]))) -np.log(1/(1+np.exp(2*x[0]+x[1])))\n",
        "\n",
        "def gradient(x, f):\n",
        "    return approx_fprime(x, f)\n",
        "\n",
        "def eta(t, const_val=0.2):\n",
        "    return const_val\n",
        "\n",
        "def eta_sqrt(t, const_val=0.2):\n",
        "    return const_val / np.sqrt(t+1)\n",
        "\n",
        "def eta_multistep(t, milestones=[20,50,80], c=0.2,  eta_init=0.2):\n",
        "    eta = eta_init\n",
        "    for milestone in milestones:\n",
        "        if t >= milestone:\n",
        "            eta *= c\n",
        "        else:\n",
        "            break\n",
        "    return eta\n",
        "\n",
        "def eta_all(t, const_val=0.2 , scenario=1, milestones=[20,50,80], eta_init=0.2, c=0.2):\n",
        "    if scenario == 1:\n",
        "        return const_val\n",
        "    elif scenario == 2:\n",
        "        return const_val / np.sqrt(t+1)\n",
        "    else:\n",
        "        eta = eta_init\n",
        "        for milestone in milestones:\n",
        "            if t >= milestone:\n",
        "                eta *= c\n",
        "            else:\n",
        "                break\n",
        "        return eta\n",
        "\n",
        "def gradient_descent (f, grad_f, eta, w_0, b_0, max_iter=100):\n",
        "    x = [w_0, b_0]\n",
        "    vals = []\n",
        "    for i in range(max_iter):\n",
        "        x = x - eta(i)*grad_f(x,f)\n",
        "        vals.append(f(x))\n",
        "    return x, vals\n",
        "\n",
        "u, vals = gradient_descent(f, gradient, eta, 1, 1)\n",
        "\n",
        "print(f(u)) # f after 100 iterations\n",
        "\n",
        "print(min(vals)) # minimum of f achieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAZzEvtK7pz7"
      },
      "source": [
        "###1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0189SDJ4xi6",
        "outputId": "052c722b-632c-404a-f324-a9bbba9d841c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.696568331413324\n",
            "1.696568331413324\n"
          ]
        }
      ],
      "source": [
        "def gradient_descent_eta_sqrt (f, grad_f, eta, w_0, b_0, max_iter=100):\n",
        "    x = [w_0, b_0]\n",
        "    vals = []\n",
        "    for i in range(max_iter):\n",
        "        x = x - eta_sqrt(i)*grad_f(x,f)\n",
        "        vals.append(f(x))\n",
        "    return x, vals\n",
        "\n",
        "u, vals = gradient_descent_eta_sqrt(f, gradient, eta, 1, 1)\n",
        "\n",
        "print(f(u)) # f after 100 iterations\n",
        "\n",
        "print(min(vals)) # minimum of f achieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DenVMZQ7sA3"
      },
      "source": [
        "###1c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnNPdZUf5J5I",
        "outputId": "8d19b059-4473-4f9d-f226-e23fd677b5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5983060933025866\n",
            "1.5983060933025866\n"
          ]
        }
      ],
      "source": [
        "def gradient_descent_multistep (f, grad_f, eta, w_0, b_0, max_iter=100):\n",
        "    x = [w_0, b_0]\n",
        "    vals = []\n",
        "    for i in range(max_iter):\n",
        "        x = x - eta_multistep(i)*grad_f(x,f)\n",
        "        vals.append(f(x))\n",
        "    return x, vals\n",
        "\n",
        "u, vals = gradient_descent_multistep(f, gradient, eta, 1, 1)\n",
        "\n",
        "print(f(u)) # f after 100 iterations\n",
        "\n",
        "print(min(vals)) # minimum of f achieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfMqI_gCy1vx"
      },
      "source": [
        "## Coordinate descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaK5u2CO7hwD"
      },
      "source": [
        "###2a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1pqIh8-7Wnh",
        "outputId": "af6976c4-eae5-4673-8449-865345d1a696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1447142425533317\n",
            "-1.5\n",
            "-1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Redefine the functions using numpy for numerical computation\n",
        "def f(x):\n",
        "    return (x[0]**4)/2 - x[0]*x[1] + x[1]**2 + x[1]*x[2] + x[2]**2\n",
        "\n",
        "def argmin_x1(x):\n",
        "    return np.cbrt(x[1]/2)\n",
        "\n",
        "def argmin_x2(x):\n",
        "    return (x[0]-x[2])/2\n",
        "\n",
        "def argmin_x3(x):\n",
        "    return -x[1]/2\n",
        "\n",
        "x_0 = [2, 3, 4]\n",
        "\n",
        "print(argmin_x1(x_0))\n",
        "print(argmin_x3(x_0))\n",
        "print(argmin_x2(x_0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en--VQeu7uc-"
      },
      "source": [
        "###2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfo3jNGn-a4X",
        "outputId": "df22a192-d7c5-438b-f7f1-65ba51ce9f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2.15443469 -1.42278265  0.71139133]\n",
            "[-0.57735027 -0.38490018  0.19245009]\n"
          ]
        }
      ],
      "source": [
        "# Function to perform coordinate descent\n",
        "def coordinate_descent(f, argmin, x_0, max_iter=100):\n",
        "    x_t = np.array(x_0, dtype=float)  # current point\n",
        "    history = []  # to store the history of points\n",
        "    vals = []\n",
        "    for _ in range(max_iter):\n",
        "        x_t[0] = argmin[0](x_t)\n",
        "        x_t[1] = argmin[1](x_t)\n",
        "        x_t[2] = argmin[2](x_t)\n",
        "\n",
        "        history.append(np.array(x_t))  # append the current point to history\n",
        "        vals.append(f(x_t))\n",
        "\n",
        "    return history, vals\n",
        "\n",
        "# Starting point\n",
        "x_0 = (1, 20, 5)\n",
        "\n",
        "# Perform coordinate descent\n",
        "history, vals = coordinate_descent(f, [argmin_x1, argmin_x2, argmin_x3], x_0)\n",
        "\n",
        "# Get the first three updates and the point of convergence\n",
        "first_three_updates = history[0]\n",
        "point_of_convergence = history[-1] if history else x_0\n",
        "\n",
        "print(first_three_updates)\n",
        "\n",
        "print(point_of_convergence)\n",
        "\n",
        "# print(min(vals), np.argmin(vals))\n",
        "# print(vals[-1])\n",
        "# print(history)\n",
        "# print(vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_tGR2by6R2"
      },
      "source": [
        "\n",
        "## Regression - polynomial features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQnCa1D_bnU",
        "outputId": "269de0af-bf7d-44db-ce3f-2af02db107cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block group\n",
            "        - HouseAge      median house age in block group\n",
            "        - AveRooms      average number of rooms per household\n",
            "        - AveBedrms     average number of bedrooms per household\n",
            "        - Population    block group population\n",
            "        - AveOccup      average number of household members\n",
            "        - Latitude      block group latitude\n",
            "        - Longitude     block group longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "california = fetch_california_housing()\n",
        "print(california.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm1utCQb_rae",
        "outputId": "ff6a1b72-68f8-4063-b95f-495133048f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20640 8\n"
          ]
        }
      ],
      "source": [
        "D = california.data\n",
        "y = california.target\n",
        "n,d = D.shape\n",
        "print(n,d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFobHbko_rT2",
        "outputId": "2b1fd721-01e1-4c5e-91ab-af8e72554fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population',\n",
              "       'AveOccup', 'Latitude', 'Longitude', 'MedInc^2', 'MedInc HouseAge',\n",
              "       'MedInc AveRooms', 'MedInc AveBedrms', 'MedInc Population',\n",
              "       'MedInc AveOccup', 'MedInc Latitude', 'MedInc Longitude',\n",
              "       'HouseAge^2', 'HouseAge AveRooms', 'HouseAge AveBedrms',\n",
              "       'HouseAge Population', 'HouseAge AveOccup', 'HouseAge Latitude',\n",
              "       'HouseAge Longitude', 'AveRooms^2', 'AveRooms AveBedrms',\n",
              "       'AveRooms Population', 'AveRooms AveOccup', 'AveRooms Latitude',\n",
              "       'AveRooms Longitude', 'AveBedrms^2', 'AveBedrms Population',\n",
              "       'AveBedrms AveOccup', 'AveBedrms Latitude', 'AveBedrms Longitude',\n",
              "       'Population^2', 'Population AveOccup', 'Population Latitude',\n",
              "       'Population Longitude', 'AveOccup^2', 'AveOccup Latitude',\n",
              "       'AveOccup Longitude', 'Latitude^2', 'Latitude Longitude',\n",
              "       'Longitude^2'], dtype=object)"
            ]
          },
          "execution_count": 308,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "aff = PolynomialFeatures(2,include_bias=True)\n",
        "X = aff.fit_transform(D)\n",
        "aff.get_feature_names_out(california.feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pSDBLEWFk3A"
      },
      "source": [
        "###3a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gc6qNic_rJm",
        "outputId": "d4927353-2807-4202-faff-3e4d60ff6c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.73724050e-14 -2.13592260e+01 -1.06836027e+01  1.59359089e+01\n",
            " -1.49711108e+01  4.59870797e-01  1.04259114e+01  1.85944716e+01\n",
            "  1.17817488e+01 -6.87088527e-01  1.38351438e-01  7.76089532e-01\n",
            " -4.81312587e-01  3.20217971e-01 -2.41849751e-01 -1.02687787e+01\n",
            " -3.28145698e+01  1.58937359e-01 -1.11068517e-01  1.89798614e-01\n",
            "  7.12683355e-02 -8.29857800e-01 -4.59332003e+00 -1.51467711e+01\n",
            "  1.46375233e+00 -2.98943332e+00 -4.49762253e-01  1.33430103e+00\n",
            "  8.27507081e+00  2.43759047e+01  1.58838710e+00  6.28802584e-01\n",
            " -8.87572700e-01 -8.00607508e+00 -2.29088003e+01  3.62708731e-02\n",
            "  1.37385160e+00  9.13690143e-01  1.97540798e+00  9.75460347e-01\n",
            "  8.48932377e+00  2.05017906e+01  9.55423699e+00  3.50155340e+01\n",
            "  1.91683558e+01]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([-21.35922597]), array([-0.48131259]), array([0.18979861]))"
            ]
          },
          "execution_count": 309,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit the linear regression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_scaled, y)\n",
        "\n",
        "print(lin_reg.coef_)\n",
        "\n",
        "coefficients = lin_reg.coef_\n",
        "\n",
        "feature_names = aff.get_feature_names_out(california.feature_names)\n",
        "\n",
        "beta_MedInc = coefficients[feature_names == 'MedInc']\n",
        "beta_MedIncAveBedrms = coefficients[feature_names == 'MedInc AveBedrms']\n",
        "beta_HouseAgeAveBedrms = coefficients[feature_names == 'HouseAge AveBedrms']\n",
        "\n",
        "(beta_MedInc, beta_MedIncAveBedrms, beta_HouseAgeAveBedrms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udZADvoF6IP"
      },
      "source": [
        "###3b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frg5PkvjF8qN",
        "outputId": "a23e673e-c0b0-4045-a2c7-b60492f1462e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.          0.21357379 -0.00105021 -0.05690276  0.05824544 -0.02695948\n",
            " -0.04721395 -0.22103214 -0.25539343 -0.05299136  0.16643446  0.01431615\n",
            "  0.11462158  0.12489324 -0.00954736  0.18241537 -0.22178782  0.07332097\n",
            " -0.07435977  0.0496919   0.02682291 -0.01958824 -0.02634901 -0.01268341\n",
            "  0.07270566 -0.01048215 -0.09268993  0.02547091 -0.07409373  0.04759123\n",
            " -0.08179332  0.04652084 -0.00979064  0.02370626 -0.067704    0.00581334\n",
            "  0.05314259 -0.03116275  0.01905879  0.04621668 -0.03654512  0.04405424\n",
            " -0.22045714  0.11926701  0.25469302]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([0.21357379]), array([0.11462158]), array([0.0496919]))"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "model = Ridge(alpha=0.1)\n",
        "\n",
        "n = len(y)\n",
        "\n",
        "X_n_scaled = (X_scaled / np.sqrt(n))\n",
        "y_n_scaled = (y / np.sqrt(n))\n",
        "\n",
        "ridge_reg = model.fit(X_n_scaled, y_n_scaled)\n",
        "\n",
        "print(ridge_reg.coef_)\n",
        "\n",
        "coefficients = ridge_reg.coef_\n",
        "\n",
        "feature_names = aff.get_feature_names_out(california.feature_names)\n",
        "\n",
        "beta_MedInc = coefficients[feature_names == 'MedInc']\n",
        "beta_MedIncAveBedrms = coefficients[feature_names == 'MedInc AveBedrms']\n",
        "beta_HouseAgeAveBedrms = coefficients[feature_names == 'HouseAge AveBedrms']\n",
        "\n",
        "(beta_MedInc, beta_MedIncAveBedrms, beta_HouseAgeAveBedrms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPo7EB5ozGH2"
      },
      "source": [
        "## Bias-var trade off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c06dEVB4LiNV",
        "outputId": "a3656de1-1c38-4e45-dc4c-cf110d3ca101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.039999999999999994\n",
            "0.006666666666666665\n"
          ]
        }
      ],
      "source": [
        "x = 0\n",
        "true_function = (np.tan(x*np.pi))\n",
        "fd1 = x + 0.2\n",
        "fd2 = 3 * x + 0.3\n",
        "fd3 = 5 * x + 0.1\n",
        "\n",
        "def mean_bias (xd, xd1, xd2, xd3):\n",
        "    f_mean=(xd1+xd2+xd3)/3\n",
        "    bias_sq = (xd-f_mean)**2\n",
        "    return bias_sq\n",
        "\n",
        "def mean_var(xd, xd1, xd2, xd3):\n",
        "    x_mean=(xd1+xd2+xd3)/3\n",
        "    xi_list=[xd1, xd2, xd3]\n",
        "    sq_list=[]\n",
        "\n",
        "    for xi in xi_list:\n",
        "        sq = (xi-x_mean)**2\n",
        "        sq_list.append(sq)\n",
        "\n",
        "    sigma=sum(sq_list)/(len(xi_list))\n",
        "\n",
        "    return sigma\n",
        "\n",
        "print (mean_bias(true_function, fd1, fd2, fd3))\n",
        "print (mean_var(true_function, fd1, fd2, fd3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L8YH1zPzGUi"
      },
      "source": [
        "## Naive Bayes - 20news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e6475d9"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['alt.atheism', 'talk.politics.guns',\n",
        "              'sci.space']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da785a92"
      },
      "source": [
        "For example, the first document in the training data is the following one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93d9448",
        "outputId": "ad0c2038-7b35-44cf-8c98-2d9cd82379ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: fcrary@ucsu.Colorado.EDU (Frank Crary)\n",
            "Subject: Re: Riddle me this...\n",
            "Nntp-Posting-Host: ucsu.colorado.edu\n",
            "Organization: University of Colorado, Boulder\n",
            "Distribution: usa\n",
            "Lines: 16\n",
            "\n",
            "In article <1r1lp1INN752@mojo.eng.umd.edu> chuck@eng.umd.edu (Chuck Harris - WA3UQV) writes:\n",
            ">>If so, why was CS often employed against tunnels in Vietnam?\n",
            "\n",
            ">CS \"tear-gas\" was used in Vietnam because it makes you wretch so hard that\n",
            ">your stomach comes out thru your throat.  Well, not quite that bad, but\n",
            ">you can't really do much to defend yourself while you are blowing cookies.\n",
            "\n",
            "I think the is BZ gas, not CS or CN. BZ gas exposure results in projectile\n",
            "vomiting, loss of essentially all muscle control, inability to concentrate\n",
            "or think rationally and fatal reactions in a significant fraction of\n",
            "the population. For that reason its use is limited to military\n",
            "applications.\n",
            "\n",
            "                                                          Frank Crary\n",
            "                                                          CU Boulder\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(train.data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1af6f97"
      },
      "source": [
        "The classes are indicated categorically with indices from zero to two by the target vector. The target names tell us which index belongs to which class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ceeda7",
        "outputId": "9542a990-9af3-4bf7-d539-3fc52a8f0cbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, ..., 1, 2, 2])"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = train.target\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad3956b",
        "outputId": "fdd4b304-3242-4750-838d-fa1b2aecaa2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['alt.atheism', 'sci.space', 'talk.politics.guns']"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ebde71a"
      },
      "source": [
        "We represent the documents in a bag of word format. That is, we create a data matrix ``D`` such that ``D[j,i]=1`` if the j-th document contains the i-th feature (word), and ``D[j,i]=0`` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "167204f0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5,token_pattern=\"[^\\W\\d_]+\", binary=True)\n",
        "D = vectorizer.fit_transform(train.data)\n",
        "D_test = vectorizer.transform(test.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a9fdf2b"
      },
      "source": [
        "We get the allocation of feature indices to words by the following array, containing the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24b0e1c5",
        "outputId": "4c4bc7a7-3692-4af4-b2a5-2d7b8e7bfb29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['aa', 'aario', 'aaron', ..., 'zoology', 'zv', 'Ã¿'], dtype=object)"
            ]
          },
          "execution_count": 317,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d57b38"
      },
      "source": [
        "For example, the word `naive` has the index 4044."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ace193",
        "outputId": "6fc2e6c4-a796-463f-ebad-a6328bfce266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4044])"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(vectorizer.get_feature_names_out() == 'naive')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GnrWs2aldWy"
      },
      "source": [
        "###5a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NyfeaZA1jnu",
        "outputId": "382561d1-e70d-4d33-e4a9-225b97776c24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.2964793082149475, 1: 0.3662754786905497, 2: 0.3372452130945028}"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_documents_per_class = {label: np.sum(y_train == label) for label in np.unique(y_train)}\n",
        "\n",
        "# Calculate the total number of documents\n",
        "n_total_documents = len(y_train)\n",
        "\n",
        "# Calculate the class prior probabilities\n",
        "class_prior_probabilities = {class_label: count / n_total_documents for class_label, count in n_documents_per_class.items()}\n",
        "\n",
        "# Return the computed class prior probabilities\n",
        "class_prior_probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf2Zu2Drlgpf"
      },
      "source": [
        "###5b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEUuQIeYRmzW",
        "outputId": "d3144328-1394-4f25-ec0d-40bf4c4c3afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-4.564489514531929\n",
            "-6.385300412553986\n",
            "-4.916448114015891\n"
          ]
        }
      ],
      "source": [
        "# Find the index of the word 'naive'\n",
        "naive_index = np.where(vectorizer.get_feature_names_out() == 'naive')[0]\n",
        "\n",
        "# Check if 'naive' is in the vocabulary, if not, its log probability is not defined\n",
        "if len(naive_index) == 0:\n",
        "    raise ValueError(\"The word 'naive' does not appear in the vocabulary.\")\n",
        "\n",
        "alpha = 1e-5\n",
        "\n",
        "indices_of_zeros = np.where(y_train == 0)[0]\n",
        "\n",
        "selected_column_data_zeros = D[indices_of_zeros, naive_index]\n",
        "\n",
        "# Counting the number of ones in that column\n",
        "num_ones_zeros = np.count_nonzero(selected_column_data_zeros == 1)\n",
        "p_x_1_given_y_0 = (alpha + num_ones_zeros) / (np.count_nonzero(y_train == 0) + alpha*(D.shape[1]))\n",
        "\n",
        "#print(num_ones_zeros)\n",
        "#print(np.count_nonzero(y_train == 0))\n",
        "#print(D.shape[1])\n",
        "#print(\"----------------------------------\")\n",
        "\n",
        "indices_of_ones = np.where(y_train == 1)[0]\n",
        "\n",
        "selected_column_data_ones = D[indices_of_ones, naive_index]\n",
        "\n",
        "# Counting the number of ones in that column\n",
        "num_ones_ones = np.count_nonzero(selected_column_data_ones == 1)\n",
        "p_x_1_given_y_1 = (alpha + num_ones_ones) / (np.count_nonzero(y_train == 1) + alpha*(D.shape[1]))\n",
        "\n",
        "#print(num_ones_ones)\n",
        "#print(np.count_nonzero(y_train == 1))\n",
        "#print(D.shape[1])\n",
        "#print(\"----------------------------------\")\n",
        "\n",
        "indices_of_twos = np.where(y_train == 2)[0]\n",
        "\n",
        "selected_column_data_twos = D[indices_of_twos, naive_index]\n",
        "\n",
        "# Counting the number of ones in that column\n",
        "num_ones_twos = np.count_nonzero(selected_column_data_twos == 1)\n",
        "p_x_1_given_y_2 = (alpha + num_ones_twos) / (np.count_nonzero(y_train == 2) + alpha*(D.shape[1]))\n",
        "\n",
        "#print(num_ones_twos)\n",
        "#print(np.count_nonzero(y_train == 2))\n",
        "#print(D.shape[1])\n",
        "#print(\"----------------------------------\")\n",
        "\n",
        "print(np.log(p_x_1_given_y_0))\n",
        "print(np.log(p_x_1_given_y_1))\n",
        "print(np.log(p_x_1_given_y_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw9ojDmCljuE"
      },
      "source": [
        "###5c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvYSdiiGlP_b",
        "outputId": "f3fedd47-53bd-4323-aa3d-92ae628caa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-18.902632741709954\n",
            "-18.902605432154125\n",
            "-18.902615418035616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-321-afc77f0b1948>:10: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
            "  print(summation(D, y_train, c, alpha))\n"
          ]
        }
      ],
      "source": [
        "def summation(D, y, c, alpha):\n",
        "    accumulator = 0\n",
        "    for i, value in enumerate(D[0]):\n",
        "        count = np.sum((D[:, i] == value) & (y == c))\n",
        "        adjusted_count = (count + alpha) / (np.sum(y == c) + alpha * D.shape[1])\n",
        "        accumulator += np.log(adjusted_count)\n",
        "    return accumulator + np.log(np.count_nonzero((y == c))/len(y))\n",
        "\n",
        "for c in range(3):\n",
        "    print(summation(D, y_train, c, alpha))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0_jq5FKo2Hj",
        "outputId": "aa9065a8-89dc-4e50-adec-0c7db7101a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-668.1991189766588\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB(alpha=1e-5)\n",
        "clf.fit(D, y_train)\n",
        "\n",
        "x0 = D[0]\n",
        "\n",
        "# Calculate the log prior for class 0\n",
        "log_prior_y0 = clf.class_log_prior_[0]\n",
        "\n",
        "# Calculate the sum of log likelihoods for each feature of x0 given class 0\n",
        "log_likelihoods_x0_given_y0 = (x0 * clf.feature_log_prob_[0]).sum()\n",
        "\n",
        "# Now calculate the log joint probability for x0 and class 0\n",
        "log_joint_probability_x0_y0 = log_prior_y0 + log_likelihoods_x0_given_y0\n",
        "\n",
        "print(log_joint_probability_x0_y0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5I-c6uGrYaT",
        "outputId": "c4c360ae-4f21-4962-a507-def30ce7d9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-685.7588171957268\n"
          ]
        }
      ],
      "source": [
        "# Calculate the log prior for class 1\n",
        "log_prior_y0 = clf.class_log_prior_[1]\n",
        "\n",
        "# Calculate the sum of log likelihoods for each feature of x0 given class 1\n",
        "log_likelihoods_x0_given_y0 = (x0 * clf.feature_log_prob_[1]).sum()\n",
        "\n",
        "# Now calculate the log joint probability for x0 and class 1\n",
        "log_joint_probability_x0_y0 = log_prior_y0 + log_likelihoods_x0_given_y0\n",
        "\n",
        "print(log_joint_probability_x0_y0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Q6ARJNrYQs",
        "outputId": "12186965-080e-4584-a264-07daa8baa358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-509.04864749384586\n"
          ]
        }
      ],
      "source": [
        "# Calculate the log prior for class 2\n",
        "log_prior_y0 = clf.class_log_prior_[2]\n",
        "\n",
        "# Calculate the sum of log likelihoods for each feature of x0 given class 2\n",
        "log_likelihoods_x0_given_y0 = (x0 * clf.feature_log_prob_[2]).sum()\n",
        "\n",
        "# Now calculate the log joint probability for x0 and class 2\n",
        "log_joint_probability_x0_y0 = log_prior_y0 + log_likelihoods_x0_given_y0\n",
        "\n",
        "print(log_joint_probability_x0_y0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTtntRFrsEXO",
        "outputId": "7836e00f-fc75-43e3-9e72-b269e015b888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scikit-learn log joint probability: -668.1991189766586\n",
            "My log joint probability: -18.902632741709954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-325-1835539d6917>:12: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
            "  my_log_joint_probability_x0_y0 = summation(D, y_train, 0, alpha)\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "clf = MultinomialNB(alpha=1e-5)\n",
        "clf.fit(D, y_train)\n",
        "\n",
        "# Get the log joint probability for the first instance and the first class\n",
        "x0 = D[0].toarray()  # Assuming X_train is a sparse matrix\n",
        "log_prior_y0 = clf.class_log_prior_[0]\n",
        "log_likelihoods_x0_given_y0 = (x0 * clf.feature_log_prob_[0]).sum()\n",
        "log_joint_probability_x0_y0 = log_prior_y0 + log_likelihoods_x0_given_y0\n",
        "\n",
        "# Compare this with your method\n",
        "my_log_joint_probability_x0_y0 = summation(D, y_train, 0, alpha)\n",
        "\n",
        "print(\"Scikit-learn log joint probability:\", log_joint_probability_x0_y0)\n",
        "print(\"My log joint probability:\", my_log_joint_probability_x0_y0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2RZIEBRzGZE"
      },
      "source": [
        "## Decision Tree - Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4771U9CzVuZi"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "D, y = iris.data, iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bbex1aZVuS1",
        "outputId": "394bbd2c-a192-40bd-c426-32fb0bae5166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ],
      "source": [
        "print(iris.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrToiuVUVt3b",
        "outputId": "eba9e7f4-cab7-4a5b-f841-1e073f18e98b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.843333333333334\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6666666666666667, -0.17476190476190478)"
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to calculate Gini impurity for a set of classes\n",
        "def gini_impurity(classes):\n",
        "    unique, counts = np.unique(classes, return_counts=True)\n",
        "    impurity = 1 - np.sum((counts / counts.sum())**2)\n",
        "    return impurity\n",
        "\n",
        "# Calculate the Gini impurity of the root node\n",
        "root_gini_impurity = gini_impurity(y)\n",
        "\n",
        "# Calculate the mean of 'sepal length'\n",
        "sepal_length_mean = np.mean(D[:, 0])\n",
        "\n",
        "print(sepal_length_mean)\n",
        "\n",
        "# Split the dataset based on the mean of 'sepal length'\n",
        "L0 = y[D[:, 0] <= sepal_length_mean]\n",
        "L1 = y[D[:, 0] > sepal_length_mean]\n",
        "\n",
        "# Calculate the Gini impurity for each of the child nodes\n",
        "L0_gini_impurity = gini_impurity(L0)\n",
        "L1_gini_impurity = gini_impurity(L1)\n",
        "\n",
        "# Calculate the weighted Gini impurity, i.e., the cost of the split\n",
        "cost_of_split = (len(L0) / len(y)) * L0_gini_impurity + (len(L1) / len(y)) * L1_gini_impurity - root_gini_impurity\n",
        "\n",
        "root_gini_impurity, cost_of_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCiuwBhSzGdD"
      },
      "source": [
        "## Kernel SVM - Digits (+open question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c132e3a4"
      },
      "outputs": [],
      "source": [
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "b7946aaa",
        "outputId": "fa001e08-f049-4893-aed4-9fcd810ce25f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "digits = datasets.load_digits()\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, digits.images, digits.target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(\"Label %i\" % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ceaddc"
      },
      "outputs": [],
      "source": [
        "# flatten the images\n",
        "n = len(digits.images)\n",
        "D = digits.images.reshape((n, -1))\n",
        "y = digits.target\n",
        "\n",
        "# Split data into 70% train and 30% test subsets\n",
        "D_train, D_test, y_train, y_test = train_test_split(\n",
        "    D, y, test_size=0.3, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zC6PWs5lrnU"
      },
      "source": [
        "###7a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP-1U8zOIKVi",
        "outputId": "8866767b-951f-4eda-effa-aa590fe36189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9555555555555556"
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create an RBF kernel SVM with specified gamma and C\n",
        "clf = SVC(kernel='rbf', gamma=0.0005, C=0.9)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(D_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = clf.predict(D_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szgx1MzcOpV5"
      },
      "source": [
        "###7 b, c and d\n",
        "\n",
        "In multiclass classification, the one-vs-one scheme involves training a separate SVM for every pair of classes. If there are N classes, this results in N*(N-1)/2 classifiers.\n",
        "\n",
        "Support vectors are the data points that are closest to the decision boundary and are critical for defining the position and orientation of the decision boundary. The decision function in an SVM is based on these support vectors, and it's used to classify new examples. The prediction for a new data point is made based on which side of the decision boundary the point lies, and this is determined by the support vectors.\n",
        "\n",
        "The prediction formula in SVM typically takes the form:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Here, x is a new data point you want to classify, xi are the support vectors, yi are the labels of the support vectors, Î±i are the learned coefficients that indicate the importance of each support vector, K is the kernel function (in this case, the Radial Basis Function or RBF kernel), and b is the bias term.\n",
        "\n",
        "In the formula, the support vectors xi are specifically the data points for which the coefficient Î±i is non-zero. In sklearn, after fitting an SVM model, the support vectors can be accessed through the support_vectors_ attribute of the trained model object.\n",
        "\n",
        "The kernel function transforms the input data into a higher-dimensional space where it may be easier to find a linear separation between classes. The RBF kernel, for example, is a popular choice because it can handle the case when the relation between class labels and attributes is nonlinear. The learned parameters in an SVM with an RBF kernel include the set of Î±i, the bias term b, and parameters of the kernel function itself, like gamma in the RBF kernel.\n",
        "\n",
        "These parameters are determined during the training process and are crucial for making accurate predictions. They are fine-tuned based on the training data to provide the best separation between classes by maximizing the margin around the decision boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU-muSrqS9G2"
      },
      "source": [
        "To plot the support vectors and explain which are the most influential for the SVM in discriminating between classes 0 and 1, we need to look at the absolute values of the dual coefficients associated with each support vector. The most influential support vectors are typically those with the largest absolute values in the dual coefficients, as they are the closest to the decision boundary.\n",
        "\n",
        "Let's move on to plotting the support vectors. We will select the four support vectors with the highest absolute dual coefficient values for each class and plot them.\n",
        "\n",
        "Here are the most influential support vectors for classes 0 and 1, with four support vectors shown for each class. These support vectors are the ones with the largest absolute values in the dual coefficients, indicating their importance in the SVM's decision-making process. They are the ones closest to the decision boundary between the two classes.\n",
        "\n",
        "In these images, you can observe the characteristics of the digits that the SVM model considers most ambiguous and thus most informative for determining the decision boundary. The support vectors for class 0 and class 1 should show features of their respective digits but may also share similarities that make them difficult to distinguish, which is why they are key in defining the separating hyperplane in the SVM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV4aCACb-x3G",
        "outputId": "f708829a-1447-4f94-bda7-5a64dc045639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([13, 18], dtype=int32),\n",
              " array([ 23,  43, 119, 127, 142, 160, 166, 172, 204, 215, 216, 237, 246,\n",
              "         27,  35,  45,  79, 118, 124, 138, 149, 164, 169, 186, 189, 190,\n",
              "        201, 218, 225, 250, 253], dtype=int32),\n",
              " array([[ 0.,  0.,  1., ..., 12.,  1.,  0.],\n",
              "        [ 0.,  0.,  0., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ...,  3.,  0.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0., 13., ...,  3.,  0.,  0.],\n",
              "        [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  3., ...,  0.,  0.,  0.]]))"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter out all classes except 0 and 1\n",
        "D_train_binary = D_train[np.isin(y_train, [0, 1])]\n",
        "y_train_binary = y_train[np.isin(y_train, [0, 1])]\n",
        "D_test_binary = D_test[np.isin(y_test, [0, 1])]\n",
        "y_test_binary = y_test[np.isin(y_test, [0, 1])]\n",
        "\n",
        "# Train an RBF kernel SVM with given parameters\n",
        "svm = SVC(kernel='rbf', gamma=0.0005, C=0.9, decision_function_shape='ovo')\n",
        "svm.fit(D_train_binary, y_train_binary)\n",
        "\n",
        "# The number of support vectors for the classifier between class 0 and 1\n",
        "n_sv_0_1 = svm.n_support_\n",
        "\n",
        "# The indices of support vectors for the classifier between class 0 and 1\n",
        "# Since we are dealing with a binary classification for class 0 and 1, we can directly access the support_\n",
        "sv_indices = svm.support_\n",
        "\n",
        "# Extracting the actual support vectors for the classifier between class 0 and 1\n",
        "sv_0_1 = svm.support_vectors_\n",
        "\n",
        "# Output the requested information\n",
        "n_sv_0_1, sv_indices, sv_0_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "2xrN7XNJ73QY",
        "outputId": "4b97183a-cc5b-4a93-edb8-2cbf08f7582d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Since we're working with a binary classification, the dual_coef_ will have only one row\n",
        "# The positive coefficients correspond to class 0 and the negative to class 1\n",
        "dual_coef_class_0 = svm.dual_coef_[0, svm.dual_coef_[0] > 0]\n",
        "dual_coef_class_1 = -svm.dual_coef_[0, svm.dual_coef_[0] < 0]  # Make them positive for comparison\n",
        "\n",
        "# Get the indices of the 4 most influential support vectors for each class\n",
        "indices_sv_class_0 = np.argsort(dual_coef_class_0)[-4:]\n",
        "indices_sv_class_1 = np.argsort(dual_coef_class_1)[-4:]\n",
        "\n",
        "# Now we extract the most influential support vectors for each class\n",
        "most_influential_sv_class_0 = sv_0_1[svm.dual_coef_[0] > 0][indices_sv_class_0]\n",
        "most_influential_sv_class_1 = sv_0_1[svm.dual_coef_[0] < 0][indices_sv_class_1]\n",
        "\n",
        "# Plotting the support vectors\n",
        "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
        "fig.suptitle('Most Influential Support Vectors for Class 0 and Class 1')\n",
        "\n",
        "# Plot the support vectors for class 0\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    ax.imshow(most_influential_sv_class_0[i].reshape(8, 8), cmap=plt.cm.gray_r)\n",
        "    ax.set_title(f\"SV Class 0 - {i+1}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "# Plot the support vectors for class 1\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    ax.imshow(most_influential_sv_class_1[i].reshape(8, 8), cmap=plt.cm.gray_r)\n",
        "    ax.set_title(f\"SV Class 1 - {i+1}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em-4NIqClxY3"
      },
      "source": [
        "###7e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTpbdrN0JmeA",
        "outputId": "95c989d4-129c-4ae8-8d1b-6fa989a30018"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'C': 4, 'gamma': 0.0005}, 0.9744073042401734)"
            ]
          },
          "execution_count": 335,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
        "    'C': [0.6, 0.8, 1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize the SVC with RBF kernel\n",
        "svc = SVC(kernel='rbf')\n",
        "\n",
        "# Setup the grid search\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Train the model on the whole dataset\n",
        "grid_search.fit(D, y)\n",
        "\n",
        "# Extract the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "(best_params, best_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
